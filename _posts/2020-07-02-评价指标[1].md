---
layout:     post
title:      评价指标[1]
subtitle:   
date:       2020-07-02
author:     Midone
header-img: img/post-bg-re-vs-ng2.jpg
catalog: True
tags:
    - 机器学习
---

### 评价指标

- TP 预测为1，真实为1
- FP 预测为1，真实为0
- TN 预测为0，真实为0
- FN 预测为0，真实为1

#### AUC
- AUC曲线纵坐标 $TPR = \frac{TP}{TP+FN}$,真正率 又名召回率(真实为1的有多少被找到)
- AUC曲线横坐标 $FPR = \frac{FP}{FP+TN}$ 假阳率(真实为0的有多少被误判)
- 为什么瞎猜的AUC为0.5?可以将人们将样本瞎猜为正的概率设为p，p又可以认为是划分正负样本阈值的一个参数,那么在理想情况下TPR=p,FRP=p,随着p增长 曲线面积为0.5
- AUC物理含义随机挑选出一个正样本和负样本,正样本的得分比负样本得分大的概率
- AUC计算公式,M为正样本数量,N为负样本数量,rank为得分从小到大的排名(分最小排第一)
$$AUC = \frac{\sum_{\text{正样本rank}}rank_i - \frac{M(M+1)}{2}}{M\times N}$$
- 上述公式 排名为rank最高的正样本 比(rank-1-(M-1))个的负样本高,排名为rank第二的正样本比(rank-1-(M-2))个的负样本高,以此类推,易得

#### KS值
- KS值定义是在roc-curve中的max(TPR-FPR)
- TPR代表找到坏人的比率,FPR代表把多少的好人误认为是坏人了,KS代表好人与坏人的区分程度

#### F1
- precision 精确率$\frac{TP}{TP+FP}$ 被预测出为1的里面有多少真为1
- recall之前说过
- P-R曲线 纵坐标 精确率 横坐标 召回率 不一定召回率是0的时候 精确率是1 反之也不一定
- F1 score $F1=\frac{2\times precision \times recall}{precision + recall}$

$$\frac{1}{F1} = 0.5 \times (\frac{1}{recall} + \frac{1}{precision})$$
- F1 macro:Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.
- F1 macro:即计算每一类类别的F1值,然后取平均
- F1 micro：比较繁琐一些,可以参考以下两个博客
- https://gongel.cn/?p=4506
- https://www.cnblogs.com/techengin/p/8962024.html
- 言简意赅, F1会计算出总TP,FP,FN值,针对每个类别加起来，再去计算F1。当分类没有分类错误(1234类 没有分到1234之外的类比如0类时) precision = recall = accraucy=F1
- 有分类错误时,FP代表预测为1类时 实际不为1类的数量 总和(这里1可以替换成1234) FN代表真实为1类 预测不为1


#### kappa
- kappa系数是一个用于检验一致性的指标,也可以用来衡量分类的效果,因为对于分类问题，所谓的一致性就是模型预测结果和实际分类结果是否一致。Kappa系数的计算是基混淆矩阵的，取值在-1到1之间。
- 基于混淆矩阵的kappa系数计算公式如下:
$$kappa = \frac{p_0 - p_e}{1 - p_e} = 1 - \frac{1-p_0}{1-p_e} = 1 - \frac{error}{\text{baseline error}}$$
其中，
$$p_0 = \frac{对角线元素之和}{整个元素之和},p_e = \frac{\sum_i 第i行元素之和* 第i列元素之和}{(矩阵所有元素之和)^2}$$,其实p0就是正确率，pe是所有类别分别对应的实际与预测数量之积 之总和 除以样本总数的平方(在现有的预测样本数量分布既定的情况下，随机打乱计算得到的平均正确率baseline)
 
- Kappa系数就可以解释为预测准确率减去Baseline得到的额外正确率，除以1减去baseline得到的剩余可提升正确率
- https://blog.csdn.net/weixin_43756456/article/details/106334076

- https://blog.csdn.net/wonner_/article/details/103542799?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param

```python
### 二次kappa
@jit
def qwk3(a1, a2, max_rat):
    assert(len(a1) == len(a2))
    a1 = np.asarray(a1, dtype=int)
    a2 = np.asarray(a2, dtype=int)

    hist1 = np.zeros((max_rat + 1, ))
    hist2 = np.zeros((max_rat + 1, ))

    o = 0
    for k in range(a1.shape[0]):
        i, j = a1[k], a2[k]
        hist1[i] += 1
        hist2[j] += 1
        o +=  (i - j) * (i - j)

    e = 0
    for i in range(max_rat + 1):
        for j in range(max_rat + 1):
            e += hist1[i] * hist2[j] * (i - j) * (i - j)

    e = e / a1.shape[0]

    return 1 - o / e
### 普通kappa
from numba import njit
@njit
def qwk3(a1, a2, max_rat=2):
    a1 = np.asarray(a1, dtype=np.int64)
    a2 = np.asarray(a2, dtype=np.int64)

    hist1 = np.zeros((max_rat + 1, ))
    hist2 = np.zeros((max_rat + 1, ))

    o = 0
    for k in range(a1.shape[0]):
        i, j = a1[k], a2[k]
        hist1[i] += 1
        hist2[j] += 1
        o +=  1 if i!=j else 0

    e = 0
    for i in range(max_rat + 1):
        for j in range(max_rat + 1):
            e += hist1[i] * hist2[j] * (1 if i!=j else 0)

    e = e / a1.shape[0]

    return 1 - o / e
```