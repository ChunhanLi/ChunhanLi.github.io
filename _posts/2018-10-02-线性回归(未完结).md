---
layout:     post
title:      线性回归(未完结)
subtitle:   线性回归(未完结）
date:       2018-10-02
author:     Midone
header-img: img/post-bg-re-vs-ng2.jpg
catalog: True
tags:
    - 统计机器学习
---

### 前言
新开学上Sta137时，又简单地回顾了下线性回归的知识，发现有些具体细节已经遗忘。毕竟Sta206已经学完了快一年了，就想着干脆把每个知识点就整理一遍。结果发现内容有点多，于是就先整理了Sta137上课需要的部分，之后部分等有空再补齐。

### Simple linear regression
- Model: $Y_i=\beta_0+\beta_1X_i+\epsilon_i$
- {$\epsilon_i$} are independent and follow a normal distribution with mean 0 and variance $\sigma^2$.
- Denote $S_{XX}=\sum(X_i-\bar X)^2,S_{YY}=\sum(Y_i-\bar Y)^2$
- Denote $S_{XY}=\sum(X_i-\bar X)(Y_i - \bar Y)$
- 可以推出 $\hat \beta_1=\frac{S_{XY}}{S_{XX}},\hat \beta_0=\bar Y - \hat \beta_1 \bar X$ （对损失函数求导 使其等于0推出/最小二乘法）
- 相关系数(Correlation coefficient)  $\rho=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$
- Estimator :
$$\hat {Cov(X,Y)}=\frac{S_{XY}}{n-1}, \hat {Var(X)}=\frac{S_{XX}}{n-1}, \hat{Var(Y)}=\frac{S_{YY}}{n-1}$$
- The fitted Y-values and residuals are:
$$\hat Y_i=\hat \beta_0+\hat \beta_1 X_i,\hat \epsilon_i=Y_i-\hat Y_i$$
- 用$e_i$去估计$\hat \epsilon_i$.
- $e_i=Y_i-\hat Y_i=(Y_i-\bar Y)-\hat \beta_1(X_i-\bar X)$
- $e_i$的一些性质：
1. $\sum_{i=0}^ne_i=0$
2. $\sum_{i=0}^nX_ie_i=0$
3. $\sum_{i=0}^n \hat Ye_i=0$
- total sum of squares(SSTO):$SSTO=\sum (Y_i-\bar Y)^2,df=n-1$
- regression sum of squares(SSR):$SSR=\sum(\hat Y_i -\bar Y)^2,df=1$
- Error sum of square(SSE):$SSE=\sum(Y_i-\hat Y_i)^2,df=n-2$
- $E(SSE)=(n-2)\sigma^2$
- LS estimators and $e_i,\hat Y_i$ are linear func of $Y_is$.
$$\hat \beta_1=\sum\frac{(X_i-\bar X)}{\sum(X_i-\bar X)^2}Y_i \stackrel{set}{=}\sum K_iY_i $$
$$\hat \beta_0=\bar Y -\hat \beta_1 \bar X=\sum(\frac{1}{n}-K_i \bar X)Y_i$$

- $\hat \beta_0, \hat \beta_1$ are normally distributed

- $E(\hat \beta_1)=\beta_1,E(\hat \beta_0)=\beta_0$
-  $\sigma^2\{\hat \beta_1 \}=\frac{\sigma^2}{\sum(X_i-\bar X)^2}$
-  $\sigma^2\{\hat \beta_0\}=\sigma^2[\frac{1}{n}+\frac{\bar X^2}{\sum(X_i-\bar X)^2}]$
-  SSTO=SSR+SSE
-  $SSE /\sigma^2$ 服从$\chi^2$分布（df=n-2）
-  $cov(e_i,\hat \beta_0)=0,\quad cov(e_i,\hat \beta_1)=0$
-  推出$e_i\text{分别与}\hat \beta_0,\hat \beta_1$独立，从而SSE与它两也独立。
-  $\frac{\hat \beta_1-\beta_1}{s\{\hat \beta_1\}}$服从自由度为n-2的t分布
-  $(1-\alpha)$Confident Interval(之后简称C.I):$\hat \beta_1\pm t(1-\alpha/2:n-2)s\{\hat \beta_1\}$
-  $\bar Y,\hat \beta_1$ uncorrelated
-  T-test
![A608DFC206CB40D499E18CBB7946B5F2?method=download&shareKey=6337d926c1a298e2b02ed3d2486f6f6d](https://note.youdao.com/yws/api/personal/file/A608DFC206CB40D499E18CBB7946B5F2?method=download&shareKey=6337d926c1a298e2b02ed3d2486f6f6d)
![BBB1F9819A8D4C0BA4190BDD165C314A?method=download&shareKey=b6239abbd90f48c11ac154192d277c77](https://note.youdao.com/yws/api/personal/file/BBB1F9819A8D4C0BA4190BDD165C314A?method=download&shareKey=b6239abbd90f48c11ac154192d277c77)

- $SSR=\sum(Y_i - \bar Y)^2=\hat \beta_1^2\sum(X_i-\bar X)^2$
- SSR与SSE独立
- SSR ~$(\sigma^2+\beta_1^2\sum(X_i-\bar X)^2)\chi_{(1)}^2$
- F-test
![CD78AE37D04543EB9D0C5084D3CA5454?method=download&shareKey=c1f3c100cb1e5c017c4858b976d6256e](https://note.youdao.com/yws/api/personal/file/CD78AE37D04543EB9D0C5084D3CA5454?method=download&shareKey=c1f3c100cb1e5c017c4858b976d6256e)
![83F9821B0A374A55856853040ECD4DA4?method=download&shareKey=6bd7b18c5e7946f4db40e346249df2ed](https://note.youdao.com/yws/api/personal/file/83F9821B0A374A55856853040ECD4DA4?method=download&shareKey=6bd7b18c5e7946f4db40e346249df2ed)
- $R^2=\frac{SSR}{SSTO}=1-\frac{SSE}{SSTO}$ # of the variability in Y can be explained by regression on X
- $R^2_{adj}=1-\frac{MSE}{MSTO}$

### Multiple regression
- $Y=X\beta+\epsilon$

- $\frac{\partial (Y-X\beta)^T(Y-X\beta)}{\partial\beta}=-2X^T(Y-X\beta)\stackrel{set}{=}0$
$\Rightarrow \beta=(X^TX)^{-1}X^TY$

-  Var($\beta$)=$\sigma^2(X^TX)^{-1}$

### 参考

- STA 206, 2017 FALL, UC Davis, Prof.Peng