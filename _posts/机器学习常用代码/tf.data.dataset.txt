#### https://blog.csdn.net/tianzhiya121/article/details/89206421
#### 读入数据
dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
####使用长度等于数据集大小的buffer size，打乱数据集。这确保了良好的改组。
dataset = dataset.shuffle(len(filenames))
#### 数据增强
dataset = dataset.map(parse_function, num_parallel_calls=4)
#### 根据可用的CPU动态设置并行调用的数量
dataset = dataset.map(train_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)
#### 抽取batch_szie
dataset = dataset.batch(batch_size)
### GPU执行在当前批次执行前向或者后向传播时，我们希望CPU处理下一个批次的数据，以便于数据批次能够迅速被GPU使用。
### 我们希望GPU被完全、时刻用于训练。我们称这种机制为消费者/生产者重叠，消费者是GPU，生产者是CPU。
### 使用tf.data，你可以轻易的做到只一点，只需要在通道末尾调用dataset.prefetch(1)。这将总是预取一个批次的数据，并且保证总有一个数据准备好被消耗。
dataset = dataset.prefetch(1)