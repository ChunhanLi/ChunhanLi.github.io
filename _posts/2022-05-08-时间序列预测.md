---
layout:     post
title:      时间序列预测
subtitle:   
date:       2022-05-08
author:     Midone
header-img: img/post-bg-re-vs-ng2.jpg
catalog: True
tags:
    - 算法比赛
---

### part1 multi-step时间序列预测策略

参考:https://zhuanlan.zhihu.com/p/308764952

说明例子：[1,2,3,4,5,6,7,8,9,10,X,Y,Z]

我们要做的是预测未来的3个时间点，X，Y，Z的序列的值，并且为了方便描述，这里我们统一仅仅使用1阶滞后特征

model1:[1,2,3,4,5,6,7,8,9],[X]

model2:[1,2,3,4,5,6,7,8,9],[Y]

model3:[1,2,3,4,5,6,7,8,9],[Z]


#### 第一种：直接多步预测

优点：模型误差不会累加
缺点：N个时间步要构建N个模型，可以考虑把滞后天数作为一个特征加入，就需要一个模型，还可以扩充样本

#### 第二种：递归多步预测

预测出X，用X作为预测Y的特征，以此类推

优点：不需要多个模型，可以利用最新lag的特征
缺点：模型误差会累积

#### 第三种：直接+递归的混合策略

思路也不复杂，和直接预测一样我们要根据n个时间步构造n个模型，还是以原来的例子为例：[1,2,3,4,5,6,7,8,9,10,X,Y,Z]

我们先构造一个3阶滞后的model 1：[8,9,10][X]，然后用model1 进行预测得到prediction(X)，然后我们构造model2 ，按照直接预测法的思路，

model2应该是无法将X作为观测样本进行训练，因此model2可以是[8,9,10][Y]，当然，使用直接预测法不一定要构造相同的n阶模型，也可以是[7,8,9,10][Y]。。。。依此类推，但是核心都是无法使用X处的数据，因为X是未知的没有观测到的值，

那么混合策略的做法是，我们用model1预测X得到prediction(X)，然后将这个prediction(X)作为model2的”观测“数据，纳入模型训练，即：

model2:[9,10,model1.prediction(X)][Y]，然后

model3：[10,model1.prediction(X),model2.prediction(Y)][Z]

。。。。依此类推。

自己理解下：也需要多个模型建模，model1就正常预测，model2就额外增加上model1对X的预测值，那构造train的时候特征也得这么做，相比于方法1，相当于多了个特征，但感觉做起来要挺复杂的，且模型与模型之间还是分开的，感觉还是加入lag时间特征，全部混合比较吊。 但是M5冠军好像用了这个也挺屌的。适合那种完全连续的时间

#### 第四种：深度学习

model 多输出：[8,9,10][X,Y,Z]

这种方法的问题就是，我们的标签如果是时序依赖的，比如时间序列预测未来3个时间步骤t+1，t+2，t+3，如果我们直接使用多输出的方式，则 t+1，t+2，t+3 三个标签我们其实是认为它们是完全独立的，但是实际上它们是存在序列依赖性的，

#### 第五种：seq2seq

第四种没有考虑标签的序列依赖的性质。因此就诞生了第五种策略，也是基于深度学习的方法。也有误差累计的作用。