---
layout:     post
title:      神经网络BP
subtitle:   神经网络BP
date:       2020-02-16
author:     Midone
header-img: img/post-bg-re-vs-ng2.jpg
catalog: True
tags:
    - 神经网络
---

### 前言
由于疫情放假，浑浑噩噩在家过了一个月，基本上没怎么学习，自感罪孽深重，遂加快脚步，争取一周能写一篇正式的博客。

这次简单推导下3层神经网络的反向传播，并用实例去检测下效果。

### 正文
我们用一个很丑陋的图简单说明是我们这次NN的结构，看不懂也没事，反正我能看懂就行hhhh~

![NN](https://github.com/ChunhanLi/ChunhanLi.github.io/blob/master/img/nn-example2.png?raw=true)

- 用$\phi(x)$代表sigmoid激活函数
- 假设$t_1,t_2$分别对应$O_1$,$O_2$的真实值,那么误差$E = \frac{1}{2}\sum(O_1-t_1)^2$.
- $IN_{k} = \sum_j(W_{jk}O_j+b_{jk})$
- $IN_{j} = \sum_i(W_{ij}O_i+b_{ij})$

接下来我们需要推出$\frac{\partial E}{\partial W_{jk}},\frac{\partial E}{\partial B_{jk}},\frac{\partial E}{\partial W_{ij}},\frac{\partial E}{\partial B_{ij}}$

$$\frac{\partial E}{W_{jk}} = \frac{\partial E}{\partial O_k}\frac{\partial O_k}{\partial {IN}_k}\frac{\partial IN_k}{\partial W_{jk}} = (O_k-T_k)O_k(1-O_k)O_j = \delta_k O_j \\\text{其中,}\delta_k = (O_k-T_k)O_k(1-O_k)$$

$$\frac{\partial E}{b_{jk}}  = (O_k-T_k)O_k(1-O_k) = \delta_k $$

$$\frac{\partial E}{W_{ij}}=O_iO_j(1-O_j)\sum_k(O_k-T_k)O_k(1-O_k)W_{jk} = 
O_i\delta_j\\\text{其中,}\delta_j = O_j(1-O_j)\sum_k\delta_kW_{jk}$$

$$\frac{\partial E}{b_{ij}}=O_j(1-O_j)\sum_k(O_k-T_k)O_k(1-O_k)W_{jk} = 
\delta_j$$

### 步骤
1. Input the data into the network and feed-forward
2. For each of the output nodes calculate $\delta_k$
3. For each of the hidden layer nodes calculate $\delta_j$
4. Calculate the changes that need to be made to the weights and bias terms:
$$\triangle W = -\eta\delta_lO_{l-1}\\\triangle b = -\eta \delta_l$$
5. Update the weights and biases across the network:
$$W + \triangle W\rightarrow W\\b+\triangle b \rightarrow b$$


### 实例 
用图中参数举例
![example](https://images2015.cnblogs.com/blog/853467/201606/853467-20160630142019140-402363317.png)

- 未迭代前
$O_{h1} = 0.5933,O_{h2} = 0.5969,O_{o1} = 0.7514,O_{o2} = 0.7729$
- 第一次
$\partial w1 = 0.000438$
$\partial w2 = 0.000877$
$\partial w3 = 0.000498$
$\partial w4 = 0.000995$
$\partial b_{i1} = 0.00876$
$\partial b_{i2} = 0.00996$
$\partial w5 = 0.0822$
$\partial w6 = 0.0827$
$\partial w7 = -0.0226$
$\partial w8 = -0.02275$
$\partial b_{j1} = 0.1385$
$\partial b_{j2} = -0.0381$
取$\eta =0.5$ 

得到第一轮参数更新:
$w1 = 0.14978$
$w2 = 0.199562$
$w3 = 0.249751$
$w4 = 0.299502$
$b_{i1} = 0.34562$
$b_{i2} = 0.34502$
$w5 = 0.3589$
$w6 = 0.40865$
$w7 = 0.5113$
$w8 = 0.5614$
$b_{j1} = 0.53075$
$b_{j2} = 0.61905$

前向传播结果:
$O_{h1} = 0.7284,O_{h1} = 0.7783,E = 0.28044$
原来E是0.2984
### 参考
- https://mlnotebook.github.io/post/neuralnetwork/
- https://www.cnblogs.com/charlotte77/p/5629865.html
- https://www.zhihu.com/search?q=%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%8E%A8%E5%AF%BC&utm_content=search_suggestion&type=content