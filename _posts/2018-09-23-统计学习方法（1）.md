---
layout:     post
title:      统计学习方法（1）
subtitle:   统计学习方法第一章读书笔记
date:       2018-09-23
author:     Chunhan Li
header-img: img/post-bg-re-vs-ng2.jpg
catalog: false
tags:
    - 机器学习
---

# 前言
第一章主要介绍了统计学习中的一些基础概念。
# 第1章 统计学习方法概论
## 1.2 监督学习
- 输入空间：输入所有可能取值的集合
- 输出空间: 输出所有可能取值的集合

每个具体输入是一个实例，通常由特征向量表示。所有特征空间存在的空间为特征空间。（输入空间和特征空间可以不同）

在本书中输入实例X的特征向量记做$X_{j}=(x^{(1)},\dots,x^{(j)},\dots,x^{(n)})$.j表示多个输入变量的第j个.i表示第i个特征。
- 假设空间：模型由输入空间到输出空间映射的集合$\Gamma$.

监督学习的模型：
1. 概率模型 由条件概率分布决定 $$P(Y|X)$$
2. 非概率模型 决策函数决定 $Y=f(X)$
## 1.3 统计学习三要素
- 模型+策略+算法
### 模型
- 条件概率分布或是决策函数（线性等等）
### 策略
- 按照什么样的准则学习或选择最优模型
- 损失函数 $L(Y,f(x))$

损失函数的几个类型：
1. 0-1损失函数
2. 平方损失 `$L(Y,f(x))=(Y-f(X))^2$`
3. 绝对损失
4. 对数损失函数`$L(Y,f(x))=-\log P(Y|X)$`

损失函数的期望是`$R_{exp}(f)=E_p[L(Y,f(x)]=\int_{X \times Y}L(Y,f(X))P(X,Y)d xd y$` 称为风险函数(Risk function)或期望损失(expected loss).目标是最小化风险函数。由于`$P(X,Y)$`未知，所以要用经验风险(empirical risk)去近似风险函数。(根据大数定律)
- `$R_{emp}=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))$`

但是现实中训练样本数目有限，所以用经验风险估计期望风险并不理想，有可能会过拟合，所以引申出概念结构风险最小化。
- 所谓结构风险最小化(structural risk minimization)等价于正则化(regularization),就是在经验风险的基础上加一个正则化项或者叫做惩罚项。举个例子，贝叶斯估计中的最大化后验概率就是一种结构风险最小化。
- `$\pi(\theta|x)\text{正比于}f(x|\theta)\pi(\theta)$` 
`$-\log(\pi(\theta|x))=-\log f(x|\theta)-\log \pi(\theta)$`先验概率就类似于惩罚项，而且先验概率大，惩罚项值低。

## 1.4 模型评估与模型选择
- 测试误差反映了学习方法对未知测试数据集的预测能力(常称为泛化能力(generalization ability))
- 过拟合：得出的模型对预测已知数据（i.e.参与训练的数据）预测效果好，对未知的数据预测效果差）比如模型复杂度过高就会出现这种情况。
- 模型选择方法：正则化与交叉验证

正则化：
1. 如果数据充足，随机将数据分成三部分。训练集(trainning set),验证集(validation set),测试集(test set).训练集用于训练模型，验证集用来模型选择，测试集用于评估效果。
2. 但实际中数据不充足，可采用交叉验证。a.简单的交叉验证，将数据随机分成两部分 训练和测试，在训练集下训练处多个模型，选出测试误差的组小的。b.S折交叉验证 首先随机地将已给数据切分为S个互不相交的大小相同的子集。利用S-1个数据块训练 用剩下的验证。最后选出评测中平均测试误差最小的模型。c。 S=N 留一交叉验证，数据少时可用。
## 1.6 泛化能力
通常通过研究泛化误差的概率上界进行的。

对于二分类问题，假设空间的有限集合`$\Gamma=\{\gamma_1,\dots,\gamma_d\}$`.存在以下定理：

$$ \text{对任意一个函数,}\gamma \in \Gamma\,\text{至少以概率}1- \delta\text{以下不等式成立}$$

$$R(\gamma)\leq \hat R(\gamma)+\epsilon(d,n,\delta)$$

$$\epsilon(d,n,\delta)=\sqrt{\frac{1}{2N}(\log d+\log {\frac{1}{\delta}})}$$

$$\text{证明见书本} $$

该定理主要说明了一个道理：训练误差小，其泛化误差也会相对小。
## 1.7生成模型与判别模型
略
## 1.8 分类问题
简单介绍几个概念
二分类中常用的评价指标
- 精确率(precision)`$P=\frac{TP}{TP+FP}$`
- 召回率(recall)`$R=\frac{TP}{TP+FN}$`
- F1值`$\frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}$`

## 1.9 标注问题
略
## 1.10 回归问题
略
$a^2$
