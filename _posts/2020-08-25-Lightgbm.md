---
layout:     post
title:      Lightgbm
subtitle:   
date:       2020-08-25
author:     Midone
header-img: img/post-bg-re-vs-ng2.jpg
catalog: True
tags:
    - 机器学习
---


#### Lightgbm 最主要3点
- Gradient-based one-side sampling Goss(单边梯度抽样算法)

Goss算法保留了梯度大（绝对值）的样本，并对梯度小的样本进行随机抽样，为了不改变样本的数据分布，在计算增益时为梯度小的样本乘以权重用于平衡

- Exclusive feature bundling 互斥特征捆绑算法

利用图算法实现? 使得互斥的特征能结合成一个特征

- leaf-wise算法
之前的树都是level-wise 基于层的生长

XGBoost 采用 Level-wise 的增长策略，方便并行计算每一层的分裂节点，提高了训练速度，但同时也因为节点增益过小增加了很多不必要的分裂，降低了计算量；LightGBM 采用 Leaf-wise 的增长策略减少了计算量，配合最大深度的限制防止过拟合，由于每次都需要计算增益最大的节点，所以无法并行分裂。


#### 其余几个点

- 直方图算法将连续特征离散化（内存占用更少/计算代价更小）

和加权分位数又有什么区别呢？

- 直方图加速

在构建叶节点的直方图时，我们还可以通过父节点的直方图与相邻叶节点的直方图相减的方式构建，从而减少了一半的计算量。在实际操作过程中，我们还可以先计算直方图小的叶子节点，然后利用直方图作差来获得直方图大的叶子节点

- 类别特征的最优分割
https://www.zhihu.com/question/266195966

#### 树模型不适合用One-hot的原因

1. 高基数特征做One-hot，每个类别上的数据就会特别少，切分增益时也会很小，其与其他特征进行竞争时都会失败，从而使得该特征的重要性会比实际低
2. 会影响决策树的学习;就会模型会在这个特征上进行切分，也会把数据切分到很多零散的小空间上，决策树学习的时候是利用统计信息，在小样本上学习统计信息，信息会不准确
3. 有列抽样的情况下，会降低其他特征被选中的概率

#### 优缺点

优点
- 直方图算法
- 互斥特征捆绑
- 单边梯度抽样
- leaf-wise
都减少了计算量;互斥特征捆绑,直方图减少了内存的消耗



#### 常用可调参数
- num_leaves
- colsample_bytree
- subsample
- num__leaves
- max_depth
- min_child_weight
- min_child_samples
- min_split_gain
- reg_alpha
- reg_lambda
#### 其余参数
- importance_type
split or gain


#### 参考
- https://blog.csdn.net/anshuai_aw1/article/details/83040541 （介绍直方图算法）
- https://www.zhihu.com/question/266195966
- https://zhuanlan.zhihu.com/p/87885678
- https://blog.csdn.net/anshuai_aw1/article/details/83275299 (处理类别变量)

